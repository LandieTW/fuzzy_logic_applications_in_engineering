{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0fa2968-5ade-4dee-884d-53aa4d94fca9",
   "metadata": {},
   "source": [
    "Fuzzy classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67091717-6c9a-4dcd-a679-e450f55aed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f59889-2eb4-4762-b290-9a7ce216d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets suppose we have a fuzzy set formed by composition, describing 5 data points\n",
    "R = np.array([\n",
    "    [1, .8, 0, .1, .2],\n",
    "    [.8, 1, .4, 0, .9],\n",
    "    [0, .4, 1, 0, 0],\n",
    "    [.1, 0, 0, 1, .5],\n",
    "    [.2, .9, 0, .5, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9af6026-d201-4497-9c7e-c9acebbb8c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.8 0.4 0.2 0.8]\n",
      " [0.8 1.  0.4 0.5 0.9]\n",
      " [0.4 0.4 1.  0.  0.4]\n",
      " [0.2 0.5 0.  1.  0.5]\n",
      " [0.8 0.9 0.4 0.5 1. ]]\n"
     ]
    }
   ],
   "source": [
    "# Lets create a composition max-min matrix (R_t . R_t)\n",
    "test = np.array([\n",
    "    [\n",
    "        max(\n",
    "            min(\n",
    "                R[i][k], R[k][j]\n",
    "            ) for k in range(R.shape[1])\n",
    "        ) for j in range(R.shape[0])\n",
    "    ] for i in range(R.shape[1])\n",
    "])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06240d58-a342-4d31-bc1f-f164de4a5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.9 1.  0.3]\n",
      " [0.4 0.7 0.7 0.2 0.4]\n",
      " [0.3 0.2 1.  0.3 0.1]\n",
      " [0.6 0.5 0.6 0.9 0.3]]\n"
     ]
    }
   ],
   "source": [
    "# Now, creating a random matrix\n",
    "rng = np.random.default_rng()\n",
    "test_random = rng.random((4, 5)).round(1)\n",
    "print(test_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a7733a-c39e-4be6-9ddd-87ebbceabe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_equivalence_relations(\n",
    "    test_composed: np.array,\n",
    "    R_t: np.array\n",
    ") -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Divide the universe X into mutually exclusive classes\n",
    "    finding by lambda-cuts the fuzzy equivalence relations\n",
    "\n",
    "    Args\n",
    "        test_composed (np.array): composition of values\n",
    "        R_t (np.array): universe X\n",
    "\n",
    "    Returns\n",
    "        dict: equivalence relations by lambda-cuts\n",
    "    \"\"\"\n",
    "        \n",
    "    classification = dict()\n",
    "    \n",
    "    for lambda_i in np.unique(R_t):\n",
    "    \n",
    "        R_lambda_composed = np.zeros((4, 5))\n",
    "        R_lambda_random = np.zeros((4, 5))\n",
    "        \n",
    "        for row in range(R_t.shape[1] - 1):\n",
    "            for column in range(R_t.shape[0] - 1):\n",
    "                \n",
    "                if (test_composed[row][column] == R_t[row][column] and test_composed[row][column] == 1):\n",
    "                    R_lambda_composed[row][column] = 1\n",
    "                elif (test_composed[row][column] == R_t[row][column] and test_composed[row][column] == lambda_i):\n",
    "                    R_lambda_composed[row][column] = 1\n",
    "        \n",
    "        print(f\"\\nR (Lambda: {lambda_i})\")\n",
    "        print(R_lambda_composed)\n",
    "    \n",
    "        rows = list()\n",
    "        relationships = list()\n",
    "        \n",
    "        for row in range(R_lambda_composed.shape[1] - 1):\n",
    "    \n",
    "            lambda_row = R_lambda_composed[row].tolist()\n",
    "    \n",
    "            if lambda_row not in rows:\n",
    "                rows.append(lambda_row)\n",
    "    \n",
    "            else:\n",
    "                idx = rows.index(lambda_row)\n",
    "                new_idx = len(rows)\n",
    "                relationship = [idx, new_idx]\n",
    "    \n",
    "                if relationship not in relationships:\n",
    "                    relationships.append(relationship)\n",
    "    \n",
    "                else:\n",
    "                    idx = relationships.index(relationship)\n",
    "                    relationship[idx].append(new_idx)\n",
    "            \n",
    "        classification[f'{lambda_i}'] = relationships\n",
    "        \n",
    "    return {key: val for key, val in classification.items() if len(val) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e085de-8027-4030-96f8-7cc9f17911d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R (Lambda: 0.0)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.1)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.2)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.4)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.5)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.8)\n",
      "[[1. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.9)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 1.0)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "Classification\n",
      "{'0.0': [[2, 3]], '0.4': [[1, 2]], '0.8': [[0, 1]]}\n"
     ]
    }
   ],
   "source": [
    "r_t = fuzzy_equivalence_relations(test, R)\n",
    "print(\"\\nClassification\")\n",
    "print(r_t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a17bb818-76af-4f59-b254-90fe83cd36d3",
   "metadata": {},
   "source": [
    "5 regions have suffered damage from a recent earthquake.\n",
    "The buildings in each region are characterized acoording to three damage levels: no damage, medium damage and serious damage.\n",
    "The percentage of buildings for a given region in each of the damage levels is given.\n",
    "\n",
    "                                   Regions\n",
    "                                   x1     x2     x3     x4     x5\n",
    "x_i1, ratio with no damage         0,3    0,2    0,1    0,7    0,4\n",
    "x_i2, ratio with medium damage     0,6    0,4    0,6    0,2    0,6\n",
    "x_i3, ratio with serious damage    0,1    0,4    0,3    0,1    0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93071b2f-9cce-4bd7-9761-c9e369e8c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [.3, .2, .1, .7, .4],\n",
    "    [.6, .4, .6, .2, .6],\n",
    "    [.1, .4, .3, .1, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e67a2b-1568-4155-ab96-b1360e0bf1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine amplitude approach\n",
    "\n",
    "def cosine_amplitude(\n",
    "    np_array: np.array\n",
    ") -> np.array:\n",
    "\n",
    "    \"\"\"\n",
    "    Each element of a relation, r_ij, results from a pairwise comparison of two data samples, x_i, x_j, \n",
    "    where the strength of the relationship between data sample x_i and data sample x_j is given \n",
    "    by the membership value expressing that strength: r_ij = mu_r(x_i, y_i)\n",
    "    The relation matrix will be of size n x n and, as will be the case for all similarity relations, \n",
    "    the matrix will be reflexive and symmetric, hance a tolerance relation.\n",
    "\n",
    "    Args\n",
    "        np_array (np.array): array with data\n",
    "\n",
    "    Returns\n",
    "        relation matrix\n",
    "    \"\"\"\n",
    "    n = np_array.shape[0]\n",
    "    R_ij = np.zeros((n, n))\n",
    "\n",
    "    for i in range(np_array.shape[0]):\n",
    "        for j in range(np_array.shape[0]):\n",
    "\n",
    "            if j >= i:\n",
    "                num = 0\n",
    "                den_i = 0\n",
    "                den_j = 0\n",
    "                \n",
    "                for k in range(np_array.shape[1]):\n",
    "                    \n",
    "                    num += np_array[i][k]*np_array[j][k]\n",
    "                    den_i += np_array[i][k]**2\n",
    "                    den_j += np_array[j][k]**2\n",
    "                \n",
    "                R_ij[i][j] = num / np.sqrt(den_i * den_j)\n",
    "                R_ij[j][i] = num / np.sqrt(den_i * den_j)\n",
    "\n",
    "    return R_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85019e4c-8f39-44d8-92cb-f4074ceebc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.83550442 0.91304348 0.6821865  0.98143298]\n",
      " [0.83550442 1.         0.93379906 0.58969198 0.73960026]\n",
      " [0.91304348 0.93379906 1.         0.44141479 0.81786082]\n",
      " [0.6821865  0.58969198 0.44141479 1.         0.75485136]\n",
      " [0.98143298 0.73960026 0.81786082 0.75485136 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "r_ij = cosine_amplitude(data.T)\n",
    "print(r_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0aa367-3f1c-4de3-9f97-792d11d33421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_min composition 3 times <-> 3 parameters\n",
    "\n",
    "def max_min_composition(\n",
    "    np_array: np.array\n",
    ") -> np.array:\n",
    "\n",
    "    \"\"\"\n",
    "    A way (composition) to find a relation T that relates \n",
    "    the same elements in universe X that R countains \n",
    "    to the same elements in universe Z that S countains.\n",
    "\n",
    "    NOTE:\n",
    "    This case is exclusive for R . R composition\n",
    "    Don't use for R . S compositions\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([\n",
    "        [\n",
    "            max(\n",
    "                min(\n",
    "                    np_array[i][k], np_array[k][j]\n",
    "                ) for k in range(np_array.shape[1])\n",
    "            ) for j in range(np_array.shape[0])\n",
    "        ] for i in range(np_array.shape[1])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2d0100-dc54-4819-9d62-c53ad66eca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Composition R3\n",
      "[[1.         0.91304348 0.91304348 0.75485136 0.98143298]\n",
      " [0.91304348 1.         0.93379906 0.75485136 0.91304348]\n",
      " [0.91304348 0.93379906 1.         0.75485136 0.91304348]\n",
      " [0.75485136 0.75485136 0.75485136 1.         0.75485136]\n",
      " [0.98143298 0.91304348 0.91304348 0.75485136 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "r_2 = max_min_composition(r_ij)\n",
    "r_3 = max_min_composition(r_2)\n",
    "print(\"\\nComposition R3\")\n",
    "print(r_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ed7e01-8a0e-46c1-9844-62cfb932b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R (Lambda: 0.44141479464782046)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.5896919751144688)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.6821865008193588)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.7396002616336387)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.7548513560963972)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.8178608201095308)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.8355044182110836)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.9130434782608697)\n",
      "[[1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.9337990556476817)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 0.9814329841314368)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "R (Lambda: 1.0)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "\n",
      "Classification\n",
      "{'0.9130434782608697': [[0, 2]], '0.9337990556476817': [[1, 2]]}\n"
     ]
    }
   ],
   "source": [
    "equivalence = fuzzy_equivalence_relations(r_3, r_ij)\n",
    "print(\"\\nClassification\")\n",
    "print(equivalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79398554-0db9-4084-a2c5-a1fb8ef46a44",
   "metadata": {},
   "source": [
    "FUZZY CLUSTERING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2898617-ad47-4ab4-bc1a-b6d66ad91529",
   "metadata": {},
   "source": [
    "Suppose we have 5 data points in a universe.\n",
    "Also, suppose we want to cluster these 5 points into 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07bceec-da89-44b6-bfca-7c406eeb6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "c = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f2f05d-c3b2-43c2-b56f-e6b70d5886b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import stirling2\n",
    "# for calculation of \"N subset K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c73cebbf-937d-4046-9107-756f550184ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_c_partitions(\n",
    "    n: int,\n",
    "    c: int\n",
    ") -> int:\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the unique C partitions\n",
    "\n",
    "    Args\n",
    "        n (int): number of points\n",
    "        c (int): number of clusters\n",
    "\n",
    "    Returns\n",
    "        int: number of cluster partitions\n",
    "    \"\"\"\n",
    "\n",
    "    return int(stirling2(n, c, exact=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85c809d4-c885-4349-964b-f22a19ef6320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "n_Mc = unique_c_partitions(n, c)\n",
    "print(n_Mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac9cb0-4239-4c57-b4ce-4c32eecc8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822382d-2327-4044-b968-fa974b7cd0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HCM_algo(\n",
    "    U: np.array,\n",
    "    v: np.array\n",
    ") -> int:\n",
    "\n",
    "    \"\"\"\n",
    "    within-class sum of squared errors approach\n",
    "    that uses a Euclidean normalization to characteriza distances\n",
    "    J(U, v)\n",
    "    U = partition matrix\n",
    "    v = vector of cluster centers\n",
    "    \"\"\"\n",
    "\n",
    "    def euclidean_distance(\n",
    "        x_k: Union[int, float],\n",
    "        v_i: Union[int, float]\n",
    "    ) -> Union[int, float]:\n",
    "        \n",
    "        \"\"\"\n",
    "        Measure (in m-dimensional feature space, Rm) between the x_k and v_i\n",
    "        x_k = kth data sample\n",
    "        v_i = ith cluster center\n",
    "        \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e95a36-ee22-42c7-ba06-fd2c3730dea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472d31f-7299-47d2-ad76-bf7604b7ceab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
